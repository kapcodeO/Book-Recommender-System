# ğŸ“š End-to-End Book Recommender System

A modular, scalable book recommender system built with Python and Streamlit that enables users to get book suggestions using collaborative filtering. It supports training from scratch or using pretrained models for faster loading.

---

## ğŸ“¦ Project Structure

```
book_recommender/
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ data_ingestion.py
â”‚   â”œâ”€â”€ data_validation.py
â”‚   â”œâ”€â”€ data_transformation.py
â”‚   â””â”€â”€ model_trainer.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ configuration.py
â”‚
â”œâ”€â”€ constant/
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ config_entity.py
â”‚
â”œâ”€â”€ exception/
â”‚   â””â”€â”€ exception_handler.py
â”‚
â”œâ”€â”€ logging/
â”‚   â””â”€â”€ log.py
â”‚
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ training_pipeline.py
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ util.py
â”‚
â”œâ”€â”€ app.py              # Streamlit UI
â”œâ”€â”€ main.py             # Entry point to run pipeline
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â””â”€â”€ setup.py
```

Additional directories:

- **artifacts/**: Automatically created by `main.py`  
  â”œâ”€â”€ `trained_model/`, `ingested_data/`, `raw_data/`, `transformed_data/`  
  â””â”€â”€ `serialized_objects/`: Contains pickled model/data

- **logs/**: Auto-created on each run. Stores execution logs.

- **pretrained_objects/**: Contains pre-trained serialized objects (models/data) to skip training phase.

---

## ğŸš€ Getting Started

### ğŸ” Clone this Repository

```bash
git clone https://github.com/kapcodeO/Book-Recommender-System.git
cd book-recommender
```

### ğŸ§± Set Up Virtual Environment

#### ğŸ”µ macOS / Linux

```bash
python3 -m venv venv
source venv/bin/activate
```

#### ğŸŸ£ Windows (CMD)

```cmd
python -m venv venv
venv\Scripts\activate
```

> To deactivate:
```bash
deactivate
```

---

## âš¡ Quick Start (Using Pretrained Models)

Once your environment is ready:

```bash
streamlit run app.py
```

This launches the Streamlit web app using pre-trained models from `pretrained_objects/` directory.

---

## ğŸ”¬ Train the Model Yourself

If you'd like to train everything from scratch:

```bash
python main.py
```

This will:
- Download data
- Ingest and validate data
- Transform data
- Train model
- Save artifacts in `/artifacts`

---

## ğŸ“Š Project Workflow Overview

### 0. Initial Research
Conducted in `research.ipynb`.

---

### 1. Set Constants
In `constant/__init__.py`:
```python
CONFIG_FILE_PATH = os.path.join(os.getcwd(), "config.yaml")
```

---

### 2. Define YAML Configuration (`config.yaml`)
```yaml pseudo code
artifacts_config:
  artifacts_dir: artifacts

data_ingestion_config:
  dataset_download_url: "https://github.com/kapcodeO/asset-strore/raw/refs/heads/main/book_data.zip"
  dataset_dir: dataset
  ingested_data_dir: ingested_data
  raw_data_dir: raw_data

data_validation_config:
  clean_data_dir: clean_data
  serialized_objects_dir: serialized_objects
  books_csv_file: books.csv
  ratings_csv_file: ratings.csv
```

---

### 3. Define Data Classes in `config_entity.py`

```python
DataIngestionConfig = namedtuple("DatasetConfig", [...])
DataValidationConfig = namedtuple("DataValidationConfig", [...])
DataTransformationConfig = namedtuple("DataTransformationConfig", [...])
ModelTrainerConfig = namedtuple("ModelTrainerConfig", [...])
ModelRecommendationConfig = namedtuple("ModelRecommendationConfig", [...])
```

---

### 4. Implement Configuration Logic (`configuration.py`)
Uses:
- `read_yaml_file()`
- Custom `AppException`
- Custom `logger`

```python
class AppConfiguration:
    def get_data_ingestion_config()
    def get_data_validation_config()
    ...
```

---

### 5. Develop Pipeline Components
Each stage like:
- `data_ingestion.py`
- `data_validation.py`
- `data_transformation.py`
- `model_trainer.py`

contains an `initiate_` method to handle specific phases.

---

### 6. Orchestrate via `training_pipeline.py`

```python
class TrainingPipeline:
    def start_training_pipeline():
        self.data_ingestion.initiate_data_ingestion()
        ...
```

---

### 7. Entry Point (`main.py`)
```python
from book_recommender.pipeline.training_pipeline import TrainingPipeline

pipeline = TrainingPipeline()
pipeline.start_training_pipeline()
```

---

### 8. Frontend (`app.py`)
Streamlit-powered interface to interact with recommendation system:
- Loads pretrained objects
- Suggests books based on input

---

## ğŸ³ Docker (Optional)

Build image:
```bash
docker build -t book-recommender .
```

Run container:
```bash
docker run -p 8501:8501 book-recommender
```

---

## ğŸ“ Logging
Every script execution logs events in the `logs/` directory.

---

## ğŸ› ï¸ Tech Stack

- Python
- Streamlit
- Pandas, NumPy, Scikit-learn
- Docker (Optional)

---

## ğŸ’¡ Author

Kapil Ojha  
ğŸ“§ [kapilojha.work@gmail.com]  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/kapilojha7/) | [GitHub](https://github.com/kapcodeO)

---

## â­ï¸ Show your Support

If you like this project, give it a â­ï¸  
Pull requests are welcome!
